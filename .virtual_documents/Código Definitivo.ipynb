


# Importar as bibliotecas
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.cluster import KMeans
from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV
from sklearn import tree
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score





dataset = pd.read_csv('tabela_2022.csv',sep = ',')





# Separa os dados em dois datasets
colunas_clusterização = ["submissions_list01", "HitsCorrects_list01",	"submissions_mean_list01",	"wrong_list01",	"partially_wrong_list01",	"Submissions_Corrects_list01",	"TimeAll_list01",	"TimeMean_list01", "Percentage_hit_list01",	"submitted_list01",	"submissions_list02", "HitsCorrects_list02",	"submissions_mean_list02",	"wrong_list02",	"partially_wrong_list02",	"Submissions_Corrects_list02",	"TimeAll_list02",	"TimeMean_list02", "Percentage_hit_list02",	"submitted_list02",	"submissions_list03", "HitsCorrects_list03",	"submissions_mean_list03",	"wrong_list03",	"partially_wrong_list03",	"Submissions_Corrects_list03",	"TimeAll_list03",	"TimeMean_list03", "Percentage_hit_list03",	"submitted_list03"]
dataset_1 = dataset[dataset["submitted_list13"] == 1.0].reset_index(drop=True)
dataset_0 = dataset[dataset["submitted_list13"] == 0.0].reset_index(drop=True)

#Separa as colunas que serão utilizadas
X0 = dataset_0.loc[:,colunas_clusterização].values


# Normaliza os dados do alunos que não submeteram a lista 13
sc = MinMaxScaler()
sc.fit(X0)
X0 = sc.transform(X0)


# Treina o modelo KMeans
kmeans = KMeans(n_clusters = 3, init = 'random', random_state = 1)
y_kmeans = kmeans.fit_predict(X0)


# Cria t-SNE para visualização gráfica em 2 dimensões
from sklearn.manifold import TSNE

data_X = dataset_0[["submissions_list01", "HitsCorrects_list01",	"submissions_mean_list01",	"wrong_list01",	"partially_wrong_list01",	"Submissions_Corrects_list01",	"TimeAll_list01",	"TimeMean_list01", "Percentage_hit_list01",	"submitted_list01",	"submissions_list02", "HitsCorrects_list02",	"submissions_mean_list02",	"wrong_list02",	"partially_wrong_list02",	"Submissions_Corrects_list02",	"TimeAll_list02",	"TimeMean_list02", "Percentage_hit_list02",	"submitted_list02",	"submissions_list03", "HitsCorrects_list03",	"submissions_mean_list03",	"wrong_list03",	"partially_wrong_list03",	"Submissions_Corrects_list03",	"TimeAll_list03",	"TimeMean_list03", "Percentage_hit_list03",	"submitted_list03"]]

# Criar o objeto TSNE
tsne = TSNE(n_components=2, perplexity=5, random_state=42)
# Aplicar o t-SNE aos dados
X_embedded = tsne.fit_transform(data_X)

# Criar o gráfico de dispersão
plt.figure(figsize=(10, 8))
sns.scatterplot(x=X_embedded[:,0], y=X_embedded[:,1], hue=y_kmeans, palette="tab10")
plt.title("Visualização dos clusters com t-SNE")
plt.xlabel("Dimensão 1")
plt.ylabel("Dimensão 2")
plt.show()


# Guarda o índice original do dataset_0
indices_originais = dataset_0.index.tolist()

# Combina os resultados do t-SNE com os índices originais
tsne_resultados = pd.DataFrame(X_embedded, columns=['tsne_feature1', 'tsne_feature2'], index=indices_originais)
print(tsne_resultados)


# Remove as linhas do dataset
dataset_0 = dataset_0.drop([74])
# Junta os dois datasets novamente
dataset = pd.concat([dataset_1, dataset_0])





# Atribui as colunas que serão utilizadas
X = dataset.iloc[:,[3,5,6,9,13,14,15,17,18,21,25,26,27,29,30,33,37,38]].values
y = dataset.iloc[:,39].values


# Separa as variáveis em treino e teste
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.25, random_state = 0)

print (X_train[0:6])





# # Normaliza os dados
# from sklearn.preprocessing import MinMaxScaler
# sc = MinMaxScaler()
# X_train = sc.fit_transform(X_train)
# X_test = sc.fit_transform(X_test)

# print(X_train[0:6])





# Treinamento utilizando o modelo de SVM
classifierSVM = SVC(C = 0.1, gamma = 'scale', kernel = 'rbf')
classifierSVM.fit(X_train,y_train) # Treinamento com dados da variável de treinamento


# Validação - Prever y_test a partir do que foi aprendido no treinamento
y_predSVM = classifierSVM.predict(X_test)

print(y_predSVM[0:20])
print(y_test[0:20])


print("Métricas - SVM")
# Calcula a acurácia
print("Acurácia: ", accuracy_score(y_test,y_predSVM)*100,"%")

# Calcula a precisão
print("Precisão:", precision_score(y_test,y_predSVM)*100," %")

# Calcula o recall
print("Recall:", recall_score(y_test,y_predSVM)*100," %")

# Calcula da precisão
print("F1_score:", f1_score(y_test,y_predSVM)*100," %")


# Mostra a matriz de confusão
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_predSVM)
print("Matriz de confusão: ")
print(cm)





# Treinamento utilizando o modelo de Árvore de Decisão
classifierDT = tree.DecisionTreeClassifier()
classifierDT.fit(X_train,y_train) # Treinamento com dados da variável de treinamento


# Validação - Prever y_test a partir do que foi aprendido no treinamento
y_predDT = classifierDT.predict(X_test)

print(y_predDT[0:20])
print(y_test[0:20])


# Cálculo de métricas do modelo Árvore de Decisão

print("Métricas - Árvore de Decisão")
# Calcula a acurácia
print("Acurácia: ", accuracy_score(y_test,y_predDT)*100,"%")

# Calcula a precisão
print("Precisão:", precision_score(y_test,y_predDT)*100," %")

# Calcula o recall
print("Recall:", recall_score(y_test,y_predDT)*100," %")

# Calcula da precisão
print("F1_score:", f1_score(y_test,y_predDT)*100," %")


# Mostra a matriz de confusão
cm = confusion_matrix(y_test, y_predDT)
print("Matriz de confusão: ")
print(cm)


# Visualiza a Árvore de Decisão
feature_names = ['submissions_list01','HitsCorrects_list01','submissions_mean_list01','Submissions_Corrects_list01','Percentage_hit_list01','submitted_list01','submissions_list02','HitsCorrects_list02','submissions_mean_list02','Submissions_Corrects_list02','Percentage_hit_list02','submitted_list02','submissions_list03','HitsCorrects_list03','submissions_mean_list03','Submissions_Corrects_list03','Percentage_hit_list03','submitted_list03']

plt.figure(figsize=(100, 100))
plot_tree(classifierDT, filled=True, feature_names=feature_names, class_names=classifierDT.classes_.astype(str),fontsize=20,proportion=True)
plt.savefig('arvore_decisao.png')
plt.show()





# Treinamento utilizando o modelo de Random Forest
classifierRF = RandomForestClassifier(bootstrap = True, max_depth = None, min_samples_leaf = 2, min_samples_split = 10, n_estimators = 300)
classifierRF.fit(X_train, y_train) # Treinamento com dados da variável de treinamento


print(X_train)


# Validação - Prever y_test a partir do que foi aprendido no treinamento
y_predRF = classifierRF.predict(X_test)

print(y_predRF[0:20])
print(y_test[0:20])


# Cálculo de métricas do modelo Random Forest

print("Métricas - Random Forest")
# Calcula a acurácia
print("Acurácia: ", accuracy_score(y_test,y_predRF)*100,"%")

# Calcula a precisão
print("Precisão:", precision_score(y_test,y_predRF)*100," %")

# Calcula o recall
print("Recall:", recall_score(y_test,y_predRF)*100," %")

# Calcula da precisão
print("F1_score:", f1_score(y_test,y_predRF)*100," %")


# Mostra a matriz de confusão
cm = confusion_matrix(y_test, y_predRF)
print("Matriz de confusão: ")
print(cm)





# Treinamento utilizando o modelo de Gaussian Naive Bayes
classifierNB = GaussianNB()
classifierNB.fit(X_train, y_train) # Treinamento com dados da variável de treinamento


# Validação - Prever y_test a partir do que foi aprendido no treinamento
y_predNB = classifierNB.predict(X_test)

print(y_predRF[0:20])
print(y_test[0:20])


# Cálculo de métricas do modelo Naive Bayes

print("Métricas - Naive Bayes")
# Calcula a acurácia
print("Acurácia: ", accuracy_score(y_test,y_predNB)*100,"%")

# Calcula a precisão
print("Precisão:", precision_score(y_test,y_predNB)*100," %")

# Calcula o recall
print("Recall:", recall_score(y_test,y_predNB)*100," %")

# Calcula da precisão
print("F1_score:", f1_score(y_test,y_predNB)*100," %")


# Mostra a matriz de confusão
cm = confusion_matrix(y_test, y_predNB)
print("Matriz de confusão: ")
print(cm)


data_turma_2024 = pd.read_csv('tabela_para_predicao.csv')


data_turma_2024





X = data_turma_2024.iloc[:,[3,5,6,9,13,14,15,17,18,21,25,26,27,29,30,33,37,38]].values


X


from sklearn.preprocessing import MinMaxScaler
sc = MinMaxScaler()
x_normalizado = sc.fit_transform(X)


y_predicao_arvore = classifierRF.predict(X)


y_predicao_arvore


cont = 0
for i in y_predicao_arvore:
    if i == 1:
        cont +=1
print(cont)



